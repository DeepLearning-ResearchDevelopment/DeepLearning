{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* *[Notice] I wrote thie code while following the examples in [Choi's Tesorflow-101 tutorial](https://github.com/sjchoi86/Tensorflow-101). And,  as I know, most of Choi's examples originally come from [Aymeric Damien's](https://github.com/aymericdamien/TensorFlow-Examples/) and  [Nathan Lintz's ](https://github.com/nlintz/TensorFlow-Tutorials) tutorials.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression with MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist      = input_data.read_data_sets('data', one_hot=True)\n",
    "X_train   = mnist.train.images\n",
    "Y_train = mnist.train.labels\n",
    "X_test    = mnist.test.images\n",
    "Y_test  = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of (X_train, X_test, Y_train, Y_test)\n",
      "((55000, 784), (10000, 784), (55000, 10), (10000, 10))\n"
     ]
    }
   ],
   "source": [
    "dimX = X_train.shape[1]\n",
    "dimY = Y_train.shape[1]\n",
    "nTrain = X_train.shape[0]\n",
    "nTest = X_test.shape[0]\n",
    "print (\"Shape of (X_train, X_test, Y_train, Y_test)\")\n",
    "print (X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Plot an example image of MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myIdx = 36436   # any number\n",
    "img   = np.reshape(X_train[myIdx, :], (28, 28)) # 28 * 28 = 784\n",
    "\n",
    "plt.matshow(img, cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Write a TF graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, dimX], name=\"input\")\n",
    "Y= tf.placeholder(tf.float32, [None, dimY], name=\"output\")\n",
    "W = tf.Variable(tf.zeros([dimX, dimY]), name=\"weight\")\n",
    "b = tf.Variable(tf.zeros([dimY]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the logic regression is  $softmax(Wx+b)$\n",
    "\n",
    "Note that the dimension of *Y_pred* is *(nBatch, dimY)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_pred = tf.nn.softmax(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a cross-entropy loss function,  $loss = -\\Sigma y'\\log(y)$\n",
    "\n",
    "*reduce_sum(X, 1)* returns the sum across the columes of the tensor *X* \n",
    "\n",
    "*reduce_mean(X)* returns the mean value for all elements of the tensor *X*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(Y_pred), reduction_indices=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "training_epochs = 50\n",
    "display_epoch = 5\n",
    "batch_size = 100   # For each time, we will use 100 samples to update parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare prediction with the true value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*argmax(X,1)*  returns the index of maximum value (which represents the label in this example) across the colums of the tensor *X*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(Y_pred, 1), tf.argmax(Y, 1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We use *with* for load a TF session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch 5)\n",
      "[Loss / Accuracy] 0.5503 / 0.8677\n",
      " \n",
      "(epoch 10)\n",
      "[Loss / Accuracy] 0.4523 / 0.8830\n",
      " \n",
      "(epoch 15)\n",
      "[Loss / Accuracy] 0.4115 / 0.8907\n",
      " \n",
      "(epoch 20)\n",
      "[Loss / Accuracy] 0.3879 / 0.8957\n",
      " \n",
      "(epoch 25)\n",
      "[Loss / Accuracy] 0.3719 / 0.8988\n",
      " \n",
      "(epoch 30)\n",
      "[Loss / Accuracy] 0.3601 / 0.9015\n",
      " \n",
      "(epoch 35)\n",
      "[Loss / Accuracy] 0.3509 / 0.9033\n",
      " \n",
      "(epoch 40)\n",
      "[Loss / Accuracy] 0.3436 / 0.9049\n",
      " \n",
      "(epoch 45)\n",
      "[Loss / Accuracy] 0.3374 / 0.9065\n",
      " \n",
      "(epoch 50)\n",
      "[Loss / Accuracy] 0.3323 / 0.9078\n",
      " \n",
      "[Test Accuracy]  0.9143\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        nBatch  = int(nTrain/batch_size)\n",
    "        myIdx =  np.random.permutation(nTrain)\n",
    "        for ii in range(nBatch):\n",
    "            X_batch = X_train[myIdx[ii*batch_size:(ii+1)*batch_size],:]\n",
    "            Y_batch = Y_train[myIdx[ii*batch_size:(ii+1)*batch_size],:]\n",
    "            sess.run(optimizer, feed_dict={X:X_batch, Y:Y_batch})\n",
    "          \n",
    "        if (epoch+1) % display_epoch == 0:\n",
    "            loss_temp = sess.run(loss, feed_dict={X: X_train, Y:Y_train}) \n",
    "            accuracy_temp = accuracy.eval({X: X_train, Y:Y_train})\n",
    "            print \"(epoch {})\".format(epoch+1) \n",
    "            print \"[Loss / Training Accuracy] {:05.4f} / {:05.4f}\".format(loss_temp, accuracy_temp)\n",
    "            print \" \"\n",
    "            \n",
    "    print \"[Test Accuracy] \",  accuracy.eval({X: X_test, Y: Y_test})   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
