{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.]\n",
      "0  cost 0.313656\n",
      "0  original [ 0.97782324  0.0273505   0.08809044 -0.1583936  -0.25792563]\n",
      "0  decoded [[ 0.33153144  0.0889487   0.08027164 -0.1954744   0.0047115 ]]\n",
      "100  cost 0.492437\n",
      "100  original [ 1.0439984  -0.15456497 -0.02051445  0.16265545  0.13649991]\n",
      "100  decoded [[ 0.484631    0.76837176 -0.14014915  0.00951893  0.03649226]]\n",
      "200  cost 0.0837414\n",
      "200  original [-0.03647321  0.87325564 -0.16859229  0.14277819 -0.0974061 ]\n",
      "200  decoded [[ 0.13416262  0.93262291 -0.17866704  0.09530924 -0.10560825]]\n",
      "300  cost 0.111759\n",
      "300  original [ 0.9590004  -0.0862577  -0.0781348  -0.12725601 -0.13609153]\n",
      "300  decoded [[ 0.94885117  0.06727643 -0.25719392 -0.18991429 -0.18888144]]\n",
      "400  cost 0.0599872\n",
      "400  original [-0.01114535  1.07348804 -0.08457679 -0.03002619 -0.23131677]\n",
      "400  decoded [[ 0.00808209  0.95142722 -0.07961246 -0.02374621 -0.28288943]]\n",
      "500  cost 0.1036\n",
      "500  original [ 1.19122401  0.02055152 -0.08767244 -0.00383402 -0.03971593]\n",
      "500  decoded [[ 0.96509528  0.04939187 -0.09415388  0.02871546 -0.06415021]]\n",
      "600  cost 0.0488946\n",
      "600  original [ 0.03543061  0.96279108 -0.07435458  0.07581847  0.09350617]\n",
      "600  decoded [[-0.07190984  0.96626008 -0.09385003  0.08205931  0.0941167 ]]\n",
      "700  cost 0.0894346\n",
      "700  original [ -5.27879225e-02   1.10106329e+00  -1.59493646e-02   2.04261075e-01\n",
      "  -6.95006849e-04]\n",
      "700  decoded [[-0.07828657  0.96728462  0.02284665  0.06578464 -0.02835322]]\n",
      "800  cost 0.0411851\n",
      "800  original [ 0.06165885  1.04518776  0.0804966  -0.00860136 -0.12733861]\n",
      "800  decoded [[ 0.0814887   0.9626984   0.09946214 -0.0194836  -0.15571497]]\n",
      "900  cost 0.0458266\n",
      "900  original [ 0.06720683  0.96175163 -0.05000873 -0.03620935 -0.15310871]\n",
      "900  decoded [[-0.01217841  0.97066486 -0.07638184 -0.04657979 -0.21069206]]\n",
      "1000  cost 0.0644728\n",
      "1000  original [-0.09092805  1.050103    0.08144617 -0.07190619 -0.00399493]\n",
      "1000  decoded [[-0.09410656  0.96717906  0.19162437 -0.08553813 -0.04364546]]\n",
      "1100  cost 0.0639775\n",
      "1100  original [ 0.02387506  1.00452084  0.14812854  0.09720412  0.01330863]\n",
      "1100  decoded [[-0.09787773  0.96810764  0.20444153  0.12891608  0.0251029 ]]\n",
      "1200  cost 0.0518631\n",
      "1200  original [ 1.05692527  0.26024301  0.02747321  0.07959331 -0.01130117]\n",
      "1200  decoded [[ 0.95730585  0.28306833 -0.02192761  0.05730202 -0.00314438]]\n",
      "1300  cost 0.0551719\n",
      "1300  original [ 0.87985888 -0.10618851  0.13638867 -0.04230325 -0.10823928]\n",
      "1300  decoded [[ 0.96030408 -0.05759545  0.13573168 -0.11874186 -0.13155593]]\n",
      "1400  cost 0.0753946\n",
      "1400  original [ 1.0570485  -0.01898217  0.05837995 -0.02331259  0.13521538]\n",
      "1400  decoded [[ 0.96213627 -0.15614012  0.07180364 -0.04355836  0.13853756]]\n",
      "1500  cost 0.0765165\n",
      "1500  original [ 0.04602197  1.07445105  0.01702836  0.04857644  0.17766364]\n",
      "1500  decoded [[ 0.03106273  0.96861106  0.10321344 -0.03878771  0.23046152]]\n",
      "1600  cost 0.0843065\n",
      "1600  original [ 1.00719868  0.07204414  0.11681594  0.07750314  0.03814729]\n",
      "1600  decoded [[ 0.96446073  0.19535902  0.22338864  0.1512873  -0.00312038]]\n",
      "1700  cost 0.0838833\n",
      "1700  original [  1.14233804e+00   1.14423952e-01  -9.92843719e-05  -7.69139631e-03\n",
      "   1.44054221e-01]\n",
      "1700  decoded [[ 0.96514535  0.143765    0.03230841  0.02813585  0.16834497]]\n",
      "1800  cost 0.054161\n",
      "1800  original [ 0.10544993  1.08306258 -0.04998753 -0.00768911 -0.05714734]\n",
      "1800  decoded [[ 0.08705197  0.96641219 -0.04010458 -0.02297785 -0.07689164]]\n",
      "1900  cost 0.0423141\n",
      "1900  original [ 0.12522551  0.89170648 -0.08582294 -0.07823955  0.10588782]\n",
      "1900  decoded [[ 0.18065087  0.96045417 -0.08614662 -0.05023788  0.08665291]]\n",
      "2000  cost 0.0548559\n",
      "2000  original [ 1.04217343 -0.08857187 -0.21550994 -0.21976875  0.11995374]\n",
      "2000  decoded [[ 0.97188157 -0.08651254 -0.20569378 -0.14552388  0.05293143]]\n",
      "2100  cost 0.126146\n",
      "2100  original [ 1.21097282  0.13483197 -0.093801    0.03238733 -0.28234974]\n",
      "2100  decoded [[ 0.96832836  0.13018717 -0.09134103  0.06778643 -0.14303912]]\n",
      "2200  cost 0.0497649\n",
      "2200  original [ 0.87224898 -0.19185944 -0.08574795 -0.0012786  -0.01362519]\n",
      "2200  decoded [[ 0.96680295 -0.24750589 -0.0997315  -0.0102066  -0.02202045]]\n",
      "2300  cost 0.0354327\n",
      "2300  original [ 0.17229141  0.90474193 -0.05682039  0.05286952 -0.01902726]\n",
      "2300  decoded [[ 0.22614989  0.95884019 -0.04129134  0.06009872 -0.00651267]]\n",
      "2400  cost 0.0925044\n",
      "2400  original [ 1.00187938  0.07980918  0.16665264  0.00565845  0.0881261 ]\n",
      "2400  decoded [[ 0.97124362  0.05267627  0.35137758 -0.03596436  0.01563614]]\n",
      "2500  cost 0.0981954\n",
      "2500  original [ -5.06724645e-04   7.49453904e-01  -2.66964523e-02  -9.79053657e-02\n",
      "  -1.64582759e-01]\n",
      "2500  decoded [[ 0.0226173   0.96152407 -0.00747485 -0.07872122 -0.12024634]]\n",
      "2600  cost 0.0613061\n",
      "2600  original [ 1.00640417  0.04065598  0.00471871 -0.03778585  0.07945385]\n",
      "2600  decoded [[ 0.97427142 -0.08654656 -0.02231137 -0.03357891  0.10827894]]\n",
      "2700  cost 0.0602038\n",
      "2700  original [-0.16581568  1.01679856  0.19674995  0.0666706   0.00204194]\n",
      "2700  decoded [[-0.15190628  0.96959889  0.08143121  0.07919604 -0.04534894]]\n",
      "2800  cost 0.0833961\n",
      "2800  original [ 0.88522187  0.03781147 -0.00567963 -0.03972193 -0.03112734]\n",
      "2800  decoded [[ 0.97113883  0.05847344  0.1413009  -0.10759436 -0.00363304]]\n",
      "2900  cost 0.0670285\n",
      "2900  original [ 0.05442661  1.1007714   0.02864921 -0.10538317 -0.02086492]\n",
      "2900  decoded [[ 0.07684772  0.9662407   0.04429774 -0.04646207 -0.03295954]]\n",
      "3000  cost 0.0863248\n",
      "3000  original [-0.05430479  1.15391113 -0.09574146 -0.0555161   0.00850794]\n",
      "3000  decoded [[-0.12090993  0.97338969 -0.10636368 -0.06554345  0.01322448]]\n",
      "3100  cost 0.0482109\n",
      "3100  original [-0.05430441  0.89269594  0.02957955 -0.05206584  0.01778289]\n",
      "3100  decoded [[ 0.01301191  0.96663624  0.04661388 -0.03316336 -0.01344768]]\n",
      "3200  cost 0.0641715\n",
      "3200  original [-0.16591516  1.08054634 -0.0611941  -0.1303476  -0.00909337]\n",
      "3200  decoded [[-0.21832903  0.96582335 -0.08250622 -0.17907226  0.03395318]]\n",
      "3300  cost 0.0339847\n",
      "3300  original [-0.0458061   0.92471515  0.02269487  0.0168128  -0.02005912]\n",
      "3300  decoded [[-0.07038961  0.96140087 -0.00741667  0.05839496  0.01442012]]\n",
      "3400  cost 0.0459231\n",
      "3400  original [-0.10847752  1.04527201 -0.26527675 -0.09801612  0.00182728]\n",
      "3400  decoded [[-0.17077349  0.96632326 -0.26107892 -0.09762479  0.02215449]]\n",
      "3500  cost 0.0887299\n",
      "3500  original [ 0.92575592 -0.07290234  0.0410933  -0.05232345  0.0420027 ]\n",
      "3500  decoded [[ 0.96302325 -0.10523367  0.15561606 -0.06408437 -0.11187073]]\n",
      "3600  cost 0.0364452\n",
      "3600  original [ 0.03213344  1.02275651  0.07788209  0.04891681 -0.05263173]\n",
      "3600  decoded [[-0.02499101  0.9672299   0.07685179  0.03520666 -0.04234498]]\n",
      "3700  cost 0.0396039\n",
      "3700  original [ 1.02932907 -0.05015106 -0.02801357  0.10431653  0.05089233]\n",
      "3700  decoded [[ 0.95500553 -0.03952731 -0.02811854  0.10551868  0.09783942]]\n",
      "3800  cost 0.0853819\n",
      "3800  original [-0.02511937  0.97965585  0.10973438 -0.01314174  0.02235273]\n",
      "3800  decoded [[ 0.12838127  0.97103304  0.18607008 -0.03336553  0.10345387]]\n",
      "3900  cost 0.0607845\n",
      "3900  original [ 0.0185374   1.08622265  0.17861856 -0.15182435 -0.0734401 ]\n",
      "3900  decoded [[ 0.07608071  0.97603202  0.18117636 -0.20612548 -0.06535055]]\n",
      "4000  cost 0.0499299\n",
      "4000  original [-0.01428193  1.04392008  0.07138144 -0.23892845  0.05485175]\n",
      "4000  decoded [[ 0.06702094  0.97149187  0.09002025 -0.25078124  0.06585474]]\n",
      "4100  cost 0.0916223\n",
      "4100  original [ 1.06070422 -0.07616446  0.0788209   0.09381017 -0.06789435]\n",
      "4100  decoded [[ 0.96431839 -0.21787624  0.0780739   0.17332985  0.01133223]]\n",
      "4200  cost 0.104487\n",
      "4200  original [ 1.08112938 -0.01031397 -0.15647204 -0.05786538 -0.03845145]\n",
      "4200  decoded [[ 0.9710803  -0.20016685 -0.17872827  0.0191281  -0.04143748]]\n",
      "4300  cost 0.0394973\n",
      "4300  original [ 0.05836307  1.0182694   0.02830904 -0.01933065 -0.17587243]\n",
      "4300  decoded [[ 0.12997106  0.96775144  0.0382685  -0.02131907 -0.18002871]]\n",
      "4400  cost 0.11611\n",
      "4400  original [ 1.18165283 -0.00251651  0.05747086 -0.0487246  -0.07734071]\n",
      "4400  decoded [[ 0.96229386 -0.00527425 -0.06182594 -0.04199114 -0.00659546]]\n",
      "4500  cost 0.0535358\n",
      "4500  original [ 0.06067653  1.09034667 -0.01289673  0.05990831 -0.18381145]\n",
      "4500  decoded [[ 0.03007256  0.97529602 -0.00476945  0.05821176 -0.17441905]]\n",
      "4600  cost 0.0971393\n",
      "4600  original [ 0.04242315  0.9970806  -0.02281058  0.07355293  0.07718224]\n",
      "4600  decoded [[ 0.2313527   0.96659285 -0.08428782  0.13057257  0.13655896]]\n",
      "4700  cost 0.0473691\n",
      "4700  original [-0.02307801  1.05135349 -0.00363487 -0.04104083  0.02559561]\n",
      "4700  decoded [[-0.08652153  0.96823519  0.00591266 -0.0454584   0.01237586]]\n",
      "4800  cost 0.0356767\n",
      "4800  original [-0.07045304  1.02566911  0.14316501  0.03461431  0.05445276]\n",
      "4800  decoded [[-0.07245238  0.9784649   0.09078471  0.03513457  0.01719761]]\n",
      "4900  cost 0.0135161\n",
      "4900  original [-0.04319499  1.001974   -0.01243615  0.01062978  0.02081597]\n",
      "4900  decoded [[-0.03207131  0.97727156 -0.01820982  0.00961256  0.00876997]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Deep Auto-Encoder implementation\n",
    "\n",
    "    An auto-encoder works as follows:\n",
    "    Data of dimension k is reduced to a lower dimension j using a matrix multiplication:\n",
    "    softmax(W*x + b)  = x'\n",
    "    \n",
    "    where W is matrix from R^k --> R^j\n",
    "    A reconstruction matrix W' maps back from R^j --> R^k\n",
    "    so our reconstruction function is softmax'(W' * x' + b') \n",
    "    Now the point of the auto-encoder is to create a reduction matrix (values for W, b) \n",
    "    that is \"good\" at reconstructing  the original data. \n",
    "    Thus we want to minimize  ||softmax'(W' * (softmax(W *x+ b)) + b')  - x||\n",
    "    A deep auto-encoder is nothing more than stacking successive layers of these reductions.\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "def create(x, layer_sizes):\n",
    "     \n",
    "    # Build the encoding layers\n",
    "    next_layer_input = x\n",
    "\n",
    "    encoding_matrices = []\n",
    "    for dim in layer_sizes:\n",
    "        input_dim = int(next_layer_input.get_shape()[1])\n",
    "\n",
    "        # Initialize W using random values in interval [-1/sqrt(n) , 1/sqrt(n)]\n",
    "        W = tf.Variable(tf.random_uniform([input_dim, dim], -1.0 / math.sqrt(input_dim), 1.0 / math.sqrt(input_dim)))\n",
    "\n",
    "        # Initialize b to zero\n",
    "        b = tf.Variable(tf.zeros([dim]))\n",
    "\n",
    "        # We are going to use tied-weights so store the W matrix for later reference.\n",
    "        encoding_matrices.append(W)\n",
    "\n",
    "        output = tf.nn.tanh(tf.matmul(next_layer_input,W) + b)\n",
    "\n",
    "        # the input into the next layer is the output of this layer\n",
    "        next_layer_input = output\n",
    "\n",
    "    # The fully encoded x value is now stored in the next_layer_input\n",
    "    encoded_x = next_layer_input\n",
    "\n",
    "    # build the reconstruction layers by reversing the reductions\n",
    "    layer_sizes.reverse()\n",
    "    encoding_matrices.reverse()\n",
    "\n",
    "\n",
    "    for i, dim in enumerate(layer_sizes[1:] + [ int(x.get_shape()[1])]) :\n",
    "        # we are using tied weights, so just lookup the encoding matrix for this step and transpose it\n",
    "        W = tf.transpose(encoding_matrices[i])\n",
    "        b = tf.Variable(tf.zeros([dim]))\n",
    "        output = tf.nn.tanh(tf.matmul(next_layer_input,W) + b)\n",
    "        next_layer_input = output\n",
    "\n",
    "    # the fully encoded and reconstructed value of x is here:\n",
    "    reconstructed_x = next_layer_input\n",
    "\n",
    "    return {\n",
    "        'encoded': encoded_x,\n",
    "        'decoded': reconstructed_x,\n",
    "        'cost' : tf.sqrt(tf.reduce_mean(tf.square(x-reconstructed_x)))\n",
    "    }\n",
    "\n",
    "def simple_test():\n",
    "    sess = tf.Session()\n",
    "    x = tf.placeholder(\"float\", [None, 4])\n",
    "    autoencoder = create(x, [2])\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(autoencoder['cost'])\n",
    "\n",
    "\n",
    "    # Our dataset consists of two centers with gaussian noise w/ sigma = 0.1\n",
    "    c1 = np.array([0,0,0.5,0])\n",
    "    c2 = np.array([0.5,0,0,0])\n",
    "\n",
    "    # do 1000 training steps\n",
    "    for i in range(2000):\n",
    "        # make a batch of 100:\n",
    "        batch = []\n",
    "        for j in range(100):\n",
    "            # pick a random centroid\n",
    "            if (random.random() > 0.5):\n",
    "                vec = c1\n",
    "            else:\n",
    "                vec = c2\n",
    "                batch.append(np.random.normal(vec, 0.1))\n",
    "        sess.run(train_step, feed_dict={x: np.array(batch)})\n",
    "        if i % 100 == 0:\n",
    "            print i, \" cost\", sess.run(autoencoder['cost'], feed_dict={x: batch})\n",
    "\n",
    "\n",
    "def deep_test():\n",
    "    sess = tf.Session()\n",
    "    start_dim = 5\n",
    "    x = tf.placeholder(\"float\", [None, start_dim])\n",
    "    autoencoder = create(x, [4, 3, 2])\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(autoencoder['cost'])\n",
    "\n",
    "\n",
    "    # Our dataset consists of two centers with gaussian noise w/ sigma = 0.1\n",
    "    c1 = np.zeros(start_dim)\n",
    "    c1[0] = 1\n",
    "\n",
    "    print c1\n",
    "\n",
    "    c2 = np.zeros(start_dim)\n",
    "    c2[1] = 1\n",
    "\n",
    "    # do 1000 training steps\n",
    "    for i in range(5000):\n",
    "        # make a batch of 100:\n",
    "        batch = []\n",
    "        for j in range(1):\n",
    "            # pick a random centroid\n",
    "            if (random.random() > 0.5):\n",
    "                vec = c1\n",
    "            else:\n",
    "                vec = c2\n",
    "            batch.append(np.random.normal(vec, 0.1))\n",
    "        sess.run(train_step, feed_dict={x: np.array(batch)})\n",
    "        if i % 100 == 0:\n",
    "            print i, \" cost\", sess.run(autoencoder['cost'], feed_dict={x: batch})\n",
    "            print i, \" original\", batch[0]\n",
    "            print i, \" decoded\", sess.run(autoencoder['decoded'], feed_dict={x: batch})\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    deep_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
