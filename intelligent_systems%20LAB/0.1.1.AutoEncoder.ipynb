{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import unittest\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import random\n",
    "sys.path.append('../../../CORE')\n",
    "from fTheanoNNclassCORE import OptionsStore, TheanoNNclass, NNsupport, FunctionModel, LayerNN\n",
    "from fGraphBuilderCORE import Graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Sampling minibatch from whole data set\n",
    "def getBatch(d, n, i):\n",
    "    idx = random.sample(i, n)\n",
    "    idx = np.sort(idx)\n",
    "    #Remove labels and read data\n",
    "    res = d[idx, 1:]\n",
    "    #Normalise output from 0..255 to 0..1\n",
    "    return res.T / 255.0\n",
    "\n",
    "#We use HDF because of its speed and convenience\n",
    "#Set data's file names and path\n",
    "srcFolder = './Data/src/'\n",
    "hdf_type = '.hdf5'\n",
    "train_set = 'mnist_train'\n",
    "test_set = 'mnist_test'\n",
    "\n",
    "#Read train data\n",
    "f_train = h5py.File(srcFolder + train_set + hdf_type, 'r+')\n",
    "DATA = f_train['/hdfDataSet']\n",
    "\n",
    "#Read CV data\n",
    "f_test = h5py.File(srcFolder + test_set + hdf_type, 'r+')\n",
    "DATA_CV = f_test['/hdfDataSet']\n",
    "\n",
    "#Print out shapes of loaded data\n",
    "print 'Data shape:', DATA.shape, '\\n', 'CV shape:', DATA_CV.shape\n",
    "\n",
    "#Extract some useful data\n",
    "dataSize = DATA.shape[0]\n",
    "cvSize = DATA_CV.shape[0]\n",
    "validDataIndexes = xrange(0, dataSize)\n",
    "\n",
    "# As we have all data we need for Auto Encoder (AE),\n",
    "# let's create an appropriate NN\n",
    "\n",
    "# Set few additional options\n",
    "numberOfFeatures = 196\n",
    "batchSize = 200\n",
    "inputSize = DATA.shape[1] - 1   # Subtract label\n",
    "iterations = 10000\n",
    "checkCvEvery = 500\n",
    "\n",
    "#Common options for whole NN\n",
    "options = OptionsStore(learnStep=0.005,\n",
    "                       rmsProp=0.9,\n",
    "                       mmsmin=1e-20,\n",
    "                       minibatch_size=batchSize,\n",
    "                       CV_size=cvSize)\n",
    "\n",
    "#First layer\n",
    "L1 = LayerNN(size_in=inputSize,\n",
    "             size_out=numberOfFeatures,\n",
    "             sparsity=0.1,\n",
    "             beta=3,\n",
    "             weightDecay=3e-3,\n",
    "             activation=FunctionModel.Sigmoid)\n",
    "\n",
    "#Second layer\n",
    "L2 = LayerNN(size_in=numberOfFeatures,\n",
    "             size_out=inputSize,\n",
    "             weightDecay=3e-3,\n",
    "             activation=FunctionModel.Sigmoid)\n",
    "\n",
    "#Compile all together\n",
    "AE = TheanoNNclass(options, (L1, L2))\n",
    "\n",
    "#Compile train and predict functions\n",
    "AE.trainCompile()\n",
    "AE.predictCompile()\n",
    "\n",
    "#Normalise CV data from 0..255 to 0..1\n",
    "X_CV = DATA_CV[:, 1:].T / 255.0\n",
    "\n",
    "#Empty list to collect CV errors\n",
    "CV_error = []\n",
    "\n",
    "#Let's iterate!\n",
    "for i in xrange(iterations):\n",
    "\n",
    "    #Get miniBatch of defined size from whole DATA\n",
    "    X = getBatch(DATA, batchSize, validDataIndexes)\n",
    "\n",
    "    #Train on given data/labels\n",
    "    AE.trainCalc(X, X, iteration=1, debug=True, errorCollect=True)\n",
    "\n",
    "    #Check CV error every *checkCvEvery* cycles\n",
    "    if i % checkCvEvery == 0:\n",
    "\n",
    "        #Caclculate CV error give CV data/labels\n",
    "        CV_error.append(NNsupport.crossV(X_CV, X_CV, AE))\n",
    "\n",
    "        #Print current CV error\n",
    "        print 'CV error: ', CV_error[-1]\n",
    "\n",
    "        #Draw how error and accuracy evolves vs iterations\n",
    "        Graph.Builder(name='AE_error.png', error=AE.errorArray, cv=CV_error, legend_on=True)\n",
    "\n",
    "        #Visualise hidden layers weights\n",
    "        AE.weightsVisualizer(folder='.', size=(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
